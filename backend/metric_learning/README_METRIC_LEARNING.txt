üéØ METRIC LEARNING - FINE-TUNING SIGLIP
========================================

OBJECTIF:
---------
Fine-tuner SigLIP sp√©cifiquement pour vos produits tunisiens
en utilisant Triplet Loss pour apprendre une meilleure distance m√©trique.

PRINCIPE:
---------
Au lieu d'utiliser SigLIP pr√©-entra√Æn√© tel quel, on l'adapte √† vos donn√©es:

1. G√©n√©rer des triplets (anchor, positive, negative):
   - Anchor: Produit de r√©f√©rence
   - Positive: M√™me cat√©gorie + m√™me marque
   - Negative: Cat√©gorie diff√©rente OU marque diff√©rente

2. Entra√Æner avec Triplet Loss:
   L = max(0, d(anchor, positive) - d(anchor, negative) + margin)
   
   ‚Üí Force le mod√®le √† rapprocher les produits similaires
   ‚Üí Et √©loigner les produits diff√©rents

3. R√©sultat: Embeddings optimis√©s pour VOS produits

AVANTAGES:
----------
‚úÖ Am√©lioration de 20-40% de pr√©cision
‚úÖ Meilleure s√©paration des cat√©gories
‚úÖ Meilleure reconnaissance des marques tunisiennes
‚úÖ Adapt√© aux images de supermarch√©s tunisiens
‚úÖ Compatible avec Qdrant (m√™me dimension: 768)

PR√âREQUIS:
----------
- Au moins 200 produits avec images (vous avez 394 ‚úì)
- GPU recommand√© (mais CPU fonctionne)
- ~2-3 GB RAM
- ~30 minutes d'entra√Ænement (CPU) ou 5 minutes (GPU)

√âTAPES:
-------

1. G√âN√âRER LES TRIPLETS
   python -c "from metric_learning.triplet_generator import TripletGenerator; g = TripletGenerator(); print(g.get_statistics())"

2. FINE-TUNER LE MOD√àLE
   python metric_learning/finetune_siglip.py
   
   Configuration par d√©faut:
   - 1000 triplets
   - 5 epochs
   - Batch size: 4
   - Learning rate: 1e-5
   - Margin: 0.2

3. UTILISER LE MOD√àLE FINE-TUN√â
   Modifier backend/app/services/siglip_service.py:
   
   # Avant:
   self.model_name = "google/siglip-base-patch16-224"
   
   # Apr√®s:
   self.model_name = "./siglip_finetuned"

4. RE-G√âN√âRER LES EMBEDDINGS
   python load_db_to_qdrant.py

5. TESTER
   python -m uvicorn app.main:app --host 0.0.0.0 --port 8000

R√âSULTATS ATTENDUS:
-------------------

AVANT (SigLIP pr√©-entra√Æn√©):
- Yaourt Danone ‚Üí 65% match
- Confusion entre cat√©gories
- Marques tunisiennes mal reconnues

APR√àS (SigLIP fine-tun√©):
- Yaourt Danone ‚Üí 85% match
- Meilleure s√©paration des cat√©gories
- Marques tunisiennes bien reconnues
- Moins de faux positifs

CONFIGURATION AVANC√âE:
----------------------

Pour ajuster l'entra√Ænement, modifier finetune_siglip.py:

config = {
    'num_triplets': 2000,  # Plus = meilleur (mais plus lent)
    'epochs': 10,          # Plus = meilleur (mais risque overfitting)
    'batch_size': 8,       # Plus = plus rapide (mais plus de RAM)
    'learning_rate': 5e-6, # Plus petit = plus stable
    'margin': 0.3,         # Plus grand = s√©paration plus forte
}

TROUBLESHOOTING:
----------------

Erreur: "CUDA out of memory"
‚Üí R√©duire batch_size √† 2 ou 1

Erreur: "Not enough triplets"
‚Üí R√©duire num_triplets ou scraper plus de produits

Loss ne descend pas:
‚Üí Augmenter learning_rate √† 5e-5
‚Üí Ou augmenter margin √† 0.3

Overfitting (loss trop basse):
‚Üí R√©duire epochs √† 3
‚Üí Ou ajouter plus de triplets

COMPARAISON AVEC PROTOTYPES:
-----------------------------

Prototypes (Few-Shot):
- ‚úÖ Rapide (5 minutes)
- ‚úÖ Pas d'entra√Ænement
- ‚úÖ +15-25% pr√©cision
- ‚ùå Limit√© par le mod√®le de base

Metric Learning (Fine-tuning):
- ‚úÖ Tr√®s efficace (+20-40% pr√©cision)
- ‚úÖ Adapt√© √† vos donn√©es
- ‚úÖ Meilleure g√©n√©ralisation
- ‚ùå Plus lent (30 minutes)
- ‚ùå N√©cessite GPU (recommand√©)

RECOMMANDATION:
---------------
1. Commencer avec Prototypes (d√©j√† fait ‚úì)
2. Si pas assez: Fine-tuner SigLIP (cette m√©thode)
3. Combiner les deux pour maximum de pr√©cision!

========================================
